{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faf15fa7-92e2-409d-94e0-f1c449518050",
   "metadata": {},
   "source": [
    "# Notebook to understand Zachary Stangbye's GPR Code\n",
    "\n",
    "The basic idea is to copy his code line-by-line, and annotate it with paragraphs/comments that help me understand it as I go along.\n",
    "\n",
    "My understanding is that the basic order of the code is the following:\n",
    "\n",
    "1. Parameter definitions\n",
    "2. Machine learning setup (grid-points generation using typicality criteria, hyperparameter bounds for GPR, state space transformation, covariance function)\n",
    "3. GPR implementation (log-likelihood function for optimization, functions to create the covariance matrix, GPR approximation functions, and storage for coefficients and transformed values\n",
    "4. Equilibrium object definitions\n",
    "5. Model-specific objects (functions to compute new bond prices, value functions for repayment and default, expected future values with quadrature integration\n",
    "6. VFI - main solution loop. Updates pricing function, value functions and policy functions, optimizes GPR hyper-parameters at each iteration, and computes coefficient vectors for GPR approximations\n",
    "\n",
    "A significant portion of this code is dedicated to bounding, then logit-transforming and finally normalizing the desired objects. All of this is for the sake of improving performance and stability within the GPR process.\n",
    "\n",
    "Here's a quick detour/aside on logit transformations: If you look it up on the internet, you'll find the following formula: \n",
    "\n",
    "**logit(p) = ln(p/(1-p))**, where p is between 0 and 1. \n",
    "\n",
    "When our object is between [a,b] instead of [0,1], we transform it with:\n",
    "\n",
    "**normalized_x = (x-a)/(b-a)**\n",
    "\n",
    "With a bit of rearranging, you will see the forms that Zach uses in his code!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a19565-cebd-4e82-9413-211dff40ccb6",
   "metadata": {},
   "source": [
    "# 1.Declaring economic parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4415aeff-044f-41ff-9ab5-b3c261581667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const max_iters = 600\n",
    "const r = 0.017\n",
    "const β = 0.953\n",
    "const σ_CRRA = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e269d7c-390d-469e-b1fd-970b175e58ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sov_utility (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sov_utility(c)\n",
    "    u = 1.0\n",
    "    if c <= 0.0\n",
    "        u = -1.0e10\n",
    "    else\n",
    "        u = c^(1-σ_CRRA)/(1-σ_CRRA)\n",
    "    end\n",
    "    return u\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0d6520d-206c-4d3e-8596-64b35084f8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07643616004405837"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const σy = 0.025 # Output shock volatility - it's like the η parameter in the QuantEcon version of this code\n",
    "const ρy = 0.945 # Output persistence      - it's like the ρ parameter in the QuantEcon version of this code\n",
    "const σy_uncond = σy/sqrt(1-ρy^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac44e70a-496c-42b1-ac0f-0480c80db253",
   "metadata": {},
   "source": [
    "### 1.1 Approximately generates the threshold-cost specification of Arellano (2008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28eab076-9d3b-47fc-8e02-d27652dbe806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ydef (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const y_const = -0.5 \n",
    "const y_curv = 0.53 \n",
    "ydef(y) = y - max(0.0,y_const*y + y_curv*y^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd77cdd0-0beb-4d6c-bef3-a89b1cb33c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.282"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const π_re_enter = 0.282 # Re-entry probability - it's the θ parameter in the Quantecon version of this code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f452848-75fd-416f-afbf-54d384ae0914",
   "metadata": {},
   "source": [
    "# 2. Declaring numerical parameters\n",
    "\n",
    "## 2.1 Bounds on y, b, q, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d43592b-c6ba-49c2-984d-f20f131f2720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0:0.006122448979591836:0.3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const stds_out = 3.0\n",
    "\n",
    "const yL = exp(-stds_out*σy_uncond)  #lowest point on the endowment grid\n",
    "const yH = exp(stds_out*σy_uncond)   #highest point on the endowment grid\n",
    "\n",
    "const bLopt = 0\n",
    "const bHopt = 0.3 \n",
    "\n",
    "const bL = bLopt-1.0e-6     #Lowest permitted borrowing\n",
    "const bH = bHopt+1.0e-6     #Highest permitted borrowing\n",
    "\n",
    "const qL = 0.0              #Lowest possible price (most expensive)\n",
    "const qH = 1/(1+r)          #Highest possible price (least expensive - the risk free price)\n",
    "\n",
    "const VL = -50.0 #-100.0\n",
    "const VH = -1.0e-6\n",
    "\n",
    "const bN_opt = 50\n",
    "const b_opt_grid = bLopt:(bHopt-bLopt)/(bN_opt-1):bHopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac04a00a-c9a7-4675-8c83-fa986d9506a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ML parameters\n",
    "const D = 2 #dimensionality of the problem - y and b in this case\n",
    "const N_inputs = 30*D #30 points per dimension in this case...\n",
    "# Scheidigger and Bilionis (2019) suggest 5*D or 10*D for N_inputs, but we\n",
    "# find this to be insufficient given the significant non-linearities in these models\n",
    "# However, the golden feature that the problem is linear in D remains\n",
    "const N_validate = 10_000   #off-grid training points to validate that it's all correct..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09f7983-ed77-47ae-af3a-10eae3f0c3e3",
   "metadata": {},
   "source": [
    "# 3. Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d94b8e9-ed18-48fc-a6af-982225258c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Plots.GRBackend()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using FastGaussQuadrature, Random, StatsFuns\n",
    "using LinearAlgebra, Optim\n",
    "using LaTeXStrings, Plots\n",
    "gr() # Sets the backend for the plotting interface (not used in solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d9ee1f-a886-4fb1-a46d-1040f5ef5ded",
   "metadata": {},
   "source": [
    "# 4 Parameterizing expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc33c6c3-567c-4a5d-b79d-ee2284ce6707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9973002039367398"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take expectations with a Gauss-Chebyshev quadrature\n",
    "# Given that there are significantly fewer grid points, it's important\n",
    "# for this to be reasonably large for precise expectations\n",
    "const quad_size = 15\n",
    "const gc_points, gc_weights = gausschebyshev(quad_size)\n",
    "\n",
    "#Quadrature nodes and weights, I guess....\n",
    "\n",
    "# Minor adjustment to quadrature-based expectations to ensure pdf integrates to unity\n",
    "const pdf_adj = normcdf(stds_out)-normcdf(-stds_out)\n",
    "#All of this adds up to pdf_adc...which in this case, is 0.997. Rescaling it so it integrates to 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6b6613-7459-4431-8342-446fc538a806",
   "metadata": {},
   "source": [
    "# NOT REALLY SURE WHAT THIS IS YET - NEED TO UPDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2857fb0c-bccd-4311-aa3f-e0f41ac0cf3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefinition of constant Main.eyeN. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60×60 Matrix{Float64}:\n",
       " 1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " ⋮                        ⋮              ⋱            ⋮                   \n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  1.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eyeN1 = zeros(N_inputs,N_inputs)\n",
    "\n",
    "#N-inputs is the number of gridpoints. Since there are 2 dimensions and 30 points per dimension, it's 60!\n",
    "#N-dimensional identity matrix....why though?\n",
    "for i=1:N_inputs\n",
    "    eyeN1[i,i] = 1.0\n",
    "end\n",
    "\n",
    "const eyeN = copy(eyeN1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900039dd-2ae1-498b-91a6-afd412a6a8f7",
   "metadata": {},
   "source": [
    "# 5. Drawing inputs/gridpoints (fixed for all iterations) from typical sets\n",
    "\n",
    "## 5.1. Why are we doing this/why aren't we just using a uniformly spaced grid?\n",
    "\n",
    "I don't think this part is strictly needed, but it helps with the code's efficiency.\n",
    "\n",
    "Basically, the Arellano (2008) model has an IRREGULAR state space. I.e. the economically relevant region of the state space doesn't fill up the entire hypercube defined by the upper and lower bounds of the state variables. Instead, the ergodic distribution of states (wthe states the economy naturally visits during simulations) forms a more complex shape like a hypersphere, simplex, etc. \n",
    "\n",
    "Putting aside how this irregular state space is constructed, creating it is important because if you create a normal uniformly-spaced grid, you'd be evaluating the function where it doesn't matter - it'd be very inefficient. You want to allocate your computational resources where the economy is actually highly likely to spend alot of time. I guess this importance becomes even bigger in higher dimensional spaces.\n",
    "\n",
    "## 5.2. So how does Zach draw out the training inputs? I.e. what is this code doing below?\n",
    "\n",
    "### 5.2.1. Gridpoint setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a25aca00-77c7-4219-8b4c-01883721555a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×60 Matrix{Float64}:\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridPointsTemp = zeros(2,N_inputs)\n",
    "gridPointsTempVec = zeros(1,N_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e98cbf0-6d21-4ffa-9fbf-4bd3d53849c2",
   "metadata": {},
   "source": [
    "**gridPointsTemp** is a 2 by N_inputs (2 by 30 in this case) matrix. It stores the coordinates for points in Arellano's 2D state-space.\n",
    "1. Row 1 (index 1) stores value for output (y)\n",
    "2. Row 2 (index 2) stores values for debt (b)\n",
    "\n",
    "**gridPointsTemp[:,i]** makes it easy to access an entire state point\n",
    "\n",
    "**gridPointsTemp[1,:]** makes it easy to access all output values (y)\n",
    "\n",
    "**gridPointsTemp[2,:]** makes it easy to access all debt values (b)\n",
    "\n",
    "**gridPointsTempVec** seems to be a temporary 1 by N_inputs vector that is used as an intermediate step when generating gridpoints for y. However, I don't think it actually does anything..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7737d9-051f-4ef0-8f2b-85bba89db2a3",
   "metadata": {},
   "source": [
    "### 5.2.2 How points for debt (b) are drawn\n",
    "\n",
    "**Stratified sampling for DEBT**\n",
    "\n",
    "**b_thresh** (0.225 in this case) is the threshold at which debt values below it are considered low, and debt values above it are considered high. \n",
    "\n",
    "**N_thresh** (20 in this case) is the number of gridpoints allocated to the low debt region. The remaining (40) points are allocated to the high debt region.\n",
    "\n",
    "The actual point creation might look a bit complicated, but **(i-1.0)/(N_thresh-1.0)** is just a value that goes from 0 to 1 as i goes from 1 to N_thresh, and all of this just ensures that you are creating a sequence of equally spaced points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0cdba64-7069-4c23-8709-1f6c4ce585cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "const b_thresh = .75*bHopt-bLopt \n",
    "const N_thresh = 10*D\n",
    "\n",
    "# We draw debt gridpoints (endogenous) from a uniform grid, adding a few more points \n",
    "# in high-debt areas even though the sovereign never goes there\n",
    "for i=1:N_inputs\n",
    "    gridPointsTempVec[i] = yL + (yH - yL)*(i-1.0)/(N_inputs-1.0)\n",
    "end \n",
    "for i=1:N_thresh\n",
    "    gridPointsTemp[2,i] = bLopt + (b_thresh-bLopt)*(i-1.0)/(N_thresh-1.0)\n",
    "end \n",
    "for i=N_thresh+1:N_inputs\n",
    "    gridPointsTemp[2,i] = b_thresh + (bHopt-b_thresh)*(i-N_thresh-1)/(N_inputs-N_thresh-1)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345efdc0-e6d2-4dea-a74c-234aef10ae07",
   "metadata": {},
   "source": [
    "### 5.2.3. How training points for output are drawn\n",
    "\n",
    "**Typical set sampling for OUTPUT**\n",
    "\n",
    "Zach does something fancy from information theory. Basically, if you have a random variable, you want to obtain its **typical set**, which contains outcomes that aren't extremely unlikely or likely. It's basically a computationally efficient way of sampling from the distribution.\n",
    "\n",
    "At a high level, this code draws N random samples from a normal distribution, calculates the empirical entropy of the entire sample, and accepts the entire batch of N points ONLY if the empirical entropy is close to the theoretical entropy. If it's not, then the code will keep redrawing new samples until it's close enough.\n",
    "\n",
    "1. The code draws random normal samples: **z_draw = σy_uncond*randn()**\n",
    "2. Converts it to log normal: **gridPointsTemp[1,i] = exp(z_draw)**\n",
    "3. Calculates the entropy of this sample: **z_draw_entropy = z_draw_entropy - log(normpdf(z_draw/σy_uncond)/σy_uncond)/N_inputs**\n",
    "4. Accepts the sample only if the empirical entropy is close enough to the theoretical entropy: **abs(z_draw_entropy - z_entropy) < typ_thresh**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b159fa4f-642b-4482-8bc6-111d42ada8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(13) # Set random seed so get same answer each time\n",
    "const typ_thresh = 1.0e-6 \n",
    "#  y is drawn to be unconditionally typical\n",
    "const z_entropy =  .5*log(2.0*π*ℯ*σy_uncond^2.0)\n",
    "not_typical = true\n",
    "while (not_typical)\n",
    "    z_draw_entropy = 0.0\n",
    "    for i=1:N_inputs \n",
    "\n",
    "        z_draw = σy_uncond*randn()\n",
    "        gridPointsTemp[1,i] = exp( z_draw )\n",
    "        z_draw_entropy = z_draw_entropy - log(normpdf(z_draw/σy_uncond)/σy_uncond)/N_inputs\n",
    "\n",
    "    end\n",
    "\n",
    "    if (  abs(z_draw_entropy - z_entropy) < typ_thresh ) \n",
    "\n",
    "        global not_typical = false \n",
    "\n",
    "    end \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37ac644-78f8-43b6-bc97-65105c7246dc",
   "metadata": {},
   "source": [
    "## 5.3 What actually goes into the GPR?\n",
    "\n",
    "So the reason it's called **gridPointsTemp** is because these aren't actually the gridpoints that we feed into the GPR. The values within here have their normal economic interpretation. However, for optimization/performance reasons, GPRs like it when the inputs are all normalized to be between 0 and 1.\n",
    "\n",
    "I.e. we actually feed a rescaled version of **gridPointTemp**, called **scaledGridPoints** into the GPR. The rescaling is done by dividing each row by the lower bound [yL;bL], and dividing it by the range [yH - yL, bH - bL)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7a583f6-dbec-4fa9-b701-25479fd53e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×60 Matrix{Float64}:\n",
       " 0.563737    0.427194   0.40771    0.530702  …  0.311511  0.593914  0.269368\n",
       " 3.33331e-6  0.0394768  0.0789502  0.118424     0.987176  0.993586  0.999997"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const gridPoints = copy(gridPointsTemp)\n",
    "const scaledGridPoints = (gridPointsTemp .- [yL;bL] )./([yH - yL; bH - bL])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224215c9-f5a7-4250-b997-b70eaccf2c4a",
   "metadata": {},
   "source": [
    "## 5.4. Solution validation\n",
    "\n",
    "The **drawConvergenceInputs** function draws random points from the state space to check for convergence. I.e. it doesn't check for convergence, but it generates num_draws number of points in the state space to validate the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a842f2a1-9d4d-461f-9446-9e38ddbe59fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drawConvergenceInputs (generic function with 1 method)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function drawConvergenceInputs(num_draws)\n",
    "    xx = zeros(2,num_draws)\n",
    "    for i=1:num_draws \n",
    "        xx[:,i] = rand(2,1).*[yH-yL;bH-bL] .+ [yL;bL]\n",
    "    end\n",
    "    return xx\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59f0191-2440-4e2c-90fc-022484eef267",
   "metadata": {},
   "source": [
    "# 6. Initializing the GPR\n",
    "\n",
    "## 6.1 Covariance function\n",
    "Zach uses the standard square exponential covariance function, but no **automatic-relevance-determination** (I think this means that the l's are all set to be the same, rather there being a different l for every training input).\n",
    "\n",
    "It takes the following inputs:\n",
    "1. x is simply the vector of training inputs\n",
    "2. xprime is the other other vector of training inputs - NEED TO VERIFY\n",
    "3. thetavec is the the vector of hyperparameters - 2D in this case. The first element is the **signal strength**, and the second one is the **length scale**.\n",
    "\n",
    "It's not that intimidating - it's simply on Zach's slides for Gaussian Process Regression IV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c47bcf9-8a63-4c69-b3c5-3d3629ac8b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "k_SE (generic function with 1 method)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function k_SE(x,xprime,θvec)\n",
    "    s = θvec[1]\n",
    "    l = θvec[2]\n",
    "    return exp( -0.5*sum( ( (x .- xprime)/l ).^2 ) + 2*log(s) )\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87406c8f-2944-4df3-8c5a-3eeeca29223f",
   "metadata": {},
   "source": [
    "## 6.2 Covariance matrix\n",
    "\n",
    "This function creates the **covariance matrix**, which is used both in likelihood maximization (**negLL function**) and in the derivation of the GPR coefficients later on in the line: VR_gprCoeff = \n",
    "\n",
    "It basically applies the k_SE function we just defined to every training input and returns a N by N covariance matrix.\n",
    "\n",
    "There is a clever trick though - note the second conditional within the two for-loops and then how the index values are flipped. What's happening, is that the for-loops are first only calculating the covariances of the **upper-half** of the covariance matrix. Then the second if statement just mirrors it, because we know that covariance matrices are symmetrical. \n",
    "\n",
    "I.e. the computation time gets halved!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1d2c6a8-4059-43ab-bea6-1234400a4cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "createK (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function createK(hyper_params,num_dims)\n",
    "\n",
    "    currK = zeros(N_inputs,N_inputs)\n",
    "\n",
    "    for ik1=1:N_inputs \n",
    "        for ik2=1:ik1 \n",
    "\n",
    "            if (num_dims == 1) \n",
    "                currK[ik1,ik2] = k_SE(scaledGridPoints[1,ik1],scaledGridPoints[1,ik2],hyper_params)\n",
    "            else \n",
    "                currK[ik1,ik2] = k_SE(scaledGridPoints[:,ik1],scaledGridPoints[:,ik2],hyper_params)\n",
    "            end \n",
    "\n",
    "            if (ik1 != ik2) \n",
    "                currK[ik2,ik1] = currK[ik1,ik2]\n",
    "            end \n",
    "\n",
    "        end \n",
    "    end \n",
    "\n",
    "    return currK\n",
    "\n",
    "end  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6692b9-672d-4e67-bdac-e9562786133d",
   "metadata": {},
   "source": [
    "## 6.3 Log-likelihood\n",
    "\n",
    "### 6.3.1 Bounds on the hyper-parameters\n",
    "\n",
    "Since this the likelihood is really important, it's crucial that it is numerically stable. Zach thus places bounds on the hyperparameters to prevent the function from exploring parameter values that are way too high. \n",
    "\n",
    "**kernSSLogLB** and **kernSSLogUB** define the bounds for the log of the **signal strength hyperparemeter**. (The first hyperparameter of the kernel)\n",
    "\n",
    "**kernLogLB** and **kernLogUB** define the bounds for the log of the **length scale hyperparameter**. (The second hyperparameter of the kernel)\n",
    "\n",
    "You might also be wondering why -2 and 8. That's because these hyperpameters are optimized in log-space. (10^log_hyper_params). I.e. the actual values explored here are between 10^-2 and 10^8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a103811e-343d-41d3-a1d2-a18ee34b5986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const kernSSLogLB = -2.0\n",
    "const kernSSLogUB = 8.0\n",
    "const kernLogLB = -2.0\n",
    "const kernLogUB = 8.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bece29c-65cc-4799-b26c-cd788e53c8c9",
   "metadata": {},
   "source": [
    "**init_kernCoeff** gives the initial guess for the hyper-parameters when the algorithm (Nelder-Meade in Zach's case) looks for the optimal set of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ce9761f-8988-412f-9e35-17e707dae53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const init_kernCoeff = [1.0;1.0] # Ensure this guess gives finite log-likelihood\n",
    "\n",
    "const sn_star = 1.0e-4 # Assumed 'measurement' noise -> sn_star^2 = 1.0e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7a060d-d47d-4249-8ed0-232ab989e783",
   "metadata": {},
   "source": [
    "### 6.3.2. Log-likelihood function\n",
    "\n",
    "The **negLL** function computes the negative of the log-likelihood for the GPR (it's negative since the Optim package finds the minimum of a function, rather than the maximum).\n",
    "\n",
    "The inputs are the following:\n",
    "1. **log_hyper_params**: logarithms of the hyperparameters (signal strength and length scale)\n",
    "2. **t_set**: training output values\n",
    "3. **num_dims**: dimensionality of the input space (this matters because the value function is only 1-D, whereas it's 2D for everything else)\n",
    "\n",
    "It works in the following order:\n",
    "1. Check if the log-parameters are within the bounds set above\n",
    "2. Convert the hyperparameters from log-space to regular-space\n",
    "3. Compute the covariance by calling the createK function\n",
    "4. Add measurement noise to the diagonal\n",
    "5. Calculate the log-likelihood.\n",
    "\n",
    "The code also does some error handling. If the parameters are out of bounds, or the covariance matrix is not positive definite (i.e. negative determinant), then it'll return a large value to steer the optimizer away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3e76662-4f95-41f1-a858-05dbc2f426aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negLL (generic function with 1 method)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function negLL(log_hyper_params, t_set, num_dims) \n",
    "\n",
    "    negLL1 = 0.0\n",
    "\n",
    "    if ( (log_hyper_params[1] > kernSSLogLB) && (log_hyper_params[1] < kernSSLogUB) && (log_hyper_params[2] > kernLogLB) && (log_hyper_params[2] < kernLogUB) )\n",
    "\n",
    "        hyper_params = 10.0.^log_hyper_params #Convert log-space hyperparams to regular space\n",
    "\n",
    "        currK =  createK(hyper_params,num_dims) #Calculate the covariance matrix\n",
    "\n",
    "        Ssigma = currK + sn_star^2.0*eyeN  #Add the noise term to the diagonal\n",
    "\n",
    "        # This way uses the standard log(|Sigma|) approach\n",
    "        temp_num = det(Ssigma)\n",
    "\n",
    "        if (temp_num > 0.0) \n",
    "            negLL1 = log(temp_num) + sum(t_set'/Ssigma*t_set)\n",
    "        else \n",
    "            negLL1 = 1.2e10\n",
    "        end  \n",
    "\n",
    "    else # If it violates the bounds, return a big number\n",
    "        negLL1 = 1.0e10 \n",
    "\n",
    "    end  \n",
    "\n",
    "    return negLL1\n",
    "\n",
    "end "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c06c494-17cc-4ef5-9bf4-c152c3d8fec4",
   "metadata": {},
   "source": [
    "## 6.5 GPR_approx function\n",
    "\n",
    "This function implements the GP posterior mean function, which predicts the function value at any point in the state space based on the training data. \n",
    "\n",
    "It takes in the following inputs:\n",
    "1. x: a SINGLE point where I want to evaluate the GP. In this problem, it's a single 2D vector (b,y) where I want to predict the function value.\n",
    "2. AA: GPR coefficients like VR_gprCoeff computed earlier by solving the linear system.\n",
    "3. kern_params: Hyperparameters of the kernel function (singal strength and length scale)\n",
    "4. xx: Matrix of of ALL training input points. I.e. scaledGridPoints\n",
    "\n",
    "It's simply implementing the tilde{m(x)} function on Slide 18, or GPR posterior. Somewhat confusingly, Zach flips the order around. AA is (K + \\sigma^2 etc.) that's been pre-computed! Note that GPR_approx1 is set to 0.0 because we assume a zero-mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abef4f89-1431-41df-9482-f4a4500a7b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPR_approx (generic function with 1 method)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function GPR_approx(x,  #Training input\n",
    "                    AA, #GPR coefficients\n",
    "                    kern_params, #Kernel hyperparameters (signal strength and length scale)\n",
    "                    xx)  #Entire matrix of training inputs (scaledGridPoints?)     \n",
    "\n",
    "    GPR_approx1 = 0.0\n",
    "\n",
    "    for i=1:N_inputs\n",
    "        GPR_approx1 = GPR_approx1 + AA[i]*k_SE(x,xx[:,i],kern_params)\n",
    "    end \n",
    "\n",
    "    return GPR_approx1\n",
    "end   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435cffe0-d0c5-4276-a201-491eb779dcdc",
   "metadata": {},
   "source": [
    "## 6.6 Constants\n",
    "\n",
    "This part of the code transforms the economic variables into oones that are suitable for GPR approximation. The functions we care about are usually bounded, but the algorithm can in principle produce any real number. Hence, we transform it to remove this possibility.\n",
    "\n",
    "There's alot going on, so here's how to read all this information: \n",
    "* If the variable has a z suffix, then they are logit-transformed. They transform bounded values to an unbounded range.\n",
    "* If the variable doesn't have a z suffix, then it is normalized transformed. I.,e., it;'s what actually gets fed into the GPR. They are centralized (zero mean) and standardized (unit variance).\n",
    "\n",
    "Basically, in the majority of the VFI step, we're dealing with variables of economic significance (e.g. vnew). Then at the GPR stage, to avoid the aforementioned issus, it gets **logit-transformed** (e.g. tset_VRz), then **normalized** (e.g. tset_VR). We need all this overhead to transform these normalized values back into values of economic significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bfd954b3-d570-4348-a8e9-afcae6b36e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60-element Vector{Float64}:\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " ⋮\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These vectors will hold the original (logit-transformed) output values\n",
    "tset_VDz = zeros(N_inputs)\n",
    "tset_VRz = zeros(N_inputs)\n",
    "tset_qz = zeros(N_inputs)\n",
    "tset_Az = zeros(N_inputs)\n",
    "\n",
    "# These vectors will hold the cleaned (logit-transformed) output values\n",
    "tset_VD = zeros(N_inputs)\n",
    "tset_VR = zeros(N_inputs)\n",
    "tset_q = zeros(N_inputs)\n",
    "tset_A = zeros(N_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4f8ec0-c7af-40a8-bd8a-e0596ab828b6",
   "metadata": {},
   "source": [
    "### 6.6.1. Remarks on the initial constants\n",
    "\n",
    "There is nothing inherently special about 500 and -500 specifically, we just needed it to be a very big number. If it's positive (500), then this corresponds to an initial guess of it being towards the lower bound. If it's negative, then it's close to the upper-bound. Note that this isn't declared as a constant, and indeed, it's it changes with every single iteration.\n",
    "\n",
    "The same happens for all the standard deviations. They are just default starting values that will get updated with each transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98d6a4f4-26dc-44c0-a8fd-afb1adcd4d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60-element Vector{Float64}:\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " ⋮\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These scalars are used to clean the output values \n",
    "mean_VD = 500.0 # With the logit transform, this corresponds to an initial zero\n",
    "mean_VR = 500.0 # With the logit transform, this corresponds to an initial zero\n",
    "mean_q = -500.0 # With the logit transform, this corresponds to an initial zero\n",
    "mean_A = -500.0 # With the logit transform, this corresponds to an initial zero\n",
    "\n",
    "std_VD = 1.0 \n",
    "std_VR = 1.0 \n",
    "std_q = 1.0 \n",
    "std_A = 1.0\n",
    "\n",
    "# These store the kernel coefficients for the approximations (signal strength, scalelength)\n",
    "VR_kernCoeff = ones(2)\n",
    "VD_kernCoeff = ones(2)\n",
    "q_kernCoeff = ones(2)\n",
    "A_kernCoeff = ones(2)\n",
    "\n",
    "# These store the GPR coefficients for the approximation \n",
    "VR_gprCoeff = zeros(N_inputs)\n",
    "VD_gprCoeff = zeros(N_inputs)\n",
    "q_gprCoeff = zeros(N_inputs)\n",
    "A_gprCoeff = zeros(N_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232c8179-4c77-4074-8fb6-2239cb19eafd",
   "metadata": {},
   "source": [
    "# 7. Equilibrium objects\n",
    "\n",
    "## 7.1. Value function for repayment\n",
    "\n",
    "These are the four functions that we want the GPR to approximate. They calculate the value of repaying, defaulting, etc. for a given **xIn**. The main thing that's a bit confusing is what this function returns.\n",
    "1. Normalize all the inputs (which are already logit transformed). into a [0,1] range\n",
    "2. Apply the GPR to get a prediction in the transformed space\n",
    "3. Apply the inverse logit transformation to map this value back into the original value range (e.g. VL, VH)\n",
    "\n",
    "The logit transformation earlier was:\n",
    "tset_VRz[i] = -log((VH-VL)/(vnew-vL) - 1.0)\n",
    "\n",
    "The majority of this line is just computing the inverse of it - i.e. undoing that logit transformation.\n",
    "\n",
    "**GPR_approx(xTransformed,VR_gprCoeff,VR_kernCoeff,scaledGridPoints)** is step 2 - applying the GPR.\n",
    "\n",
    "Deducting **mean_VR** and multiplying by **std_VR** is **un-normalizing** the value. The rest is undoing the **logit transformation**. The output is now of economic significance!\n",
    "\n",
    "However, these functions don't contain economic structure within them! They just house GPR evaluation, and are purely computational. The actual economic logic is housed within the functions in the next section with the **new_** prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c97c4988-9161-4393-83a0-62775b264f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vRepay (generic function with 1 method)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function vRepay(xIn) # Repayment value (Y_t, B_t)\n",
    "\n",
    "    xTransformed = zeros(2) \n",
    "    xTransformed[1] = (xIn[1] - yL)/(yH - yL) #Normalizes y to between [0,1]\n",
    "    xTransformed[2] = (xIn[2] - bL)/(bH - bL) #Normalizes b to between [0,1]\n",
    "    #This normalization apparently helps the GPR work better by keeping all inputs in a constant range\n",
    "    return VL + (VH - VL)/(1.0 + exp(-std_VR*GPR_approx(xTransformed,VR_gprCoeff,VR_kernCoeff,scaledGridPoints)-mean_VR))\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cccaac-a57e-4059-a250-63a31aa05220",
   "metadata": {},
   "source": [
    "## 7.2. Value function for default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fbe9b50e-155e-4b92-9dff-99869bf05a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vDefault (generic function with 1 method)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function vDefault(xIn) # Default value (Y_t)\n",
    "\n",
    "    xTransformed = (xIn - yL)/(yH - yL)\n",
    "\n",
    "    return VL + (VH - VL)/(1.0 + exp(-std_VD*GPR_approx(xTransformed,VD_gprCoeff,VD_kernCoeff,scaledGridPoints[1,:]')-mean_VD))\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d5ac8c-d0b1-4754-89e5-cc89c3accc1e",
   "metadata": {},
   "source": [
    "## 7.3. Bond pricing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96778f88-e44f-49a6-be99-8d078c776884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q (generic function with 1 method)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function q(xIn) # Pricing function (Y_t, B_t+1)\n",
    "\n",
    "    xTransformed = zeros(2) \n",
    "    xTransformed[1] = (xIn[1] - yL)/(yH - yL)\n",
    "    xTransformed[2] = (xIn[2] - bL)/(bH - bL)\n",
    "\n",
    "    return qL + (qH - qL)/(1.0 + exp(-std_q*GPR_approx(xTransformed,q_gprCoeff,q_kernCoeff,scaledGridPoints)-mean_q))\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bf6ace-2901-4c6e-9ae4-15dd0142f7e2",
   "metadata": {},
   "source": [
    "## 7.4: Bond issuance policy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4310450-9db6-4083-90bf-5439c9d33bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Apol (generic function with 1 method)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function Apol(xIn) # Borrowing policy (Y_t, B_t)\n",
    "\n",
    "    xTransformed = zeros(2) \n",
    "    xTransformed[1] = (xIn[1] - yL)/(yH - yL)\n",
    "    xTransformed[2] = (xIn[2] - bL)/(bH - bL)\n",
    "\n",
    "    return bL + (bH - bL)/(1.0 + exp(-std_A*GPR_approx(xTransformed,A_gprCoeff,A_kernCoeff,scaledGridPoints)-mean_A))\n",
    "\n",
    "end "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57efd130-7787-4e4e-9d06-f0a58f37732e",
   "metadata": {},
   "source": [
    "## 7.5 Default policy function\n",
    "\n",
    "**defFun** is the default policy function. It takes in the state variables (just x for (b,y)), and returns 1.0 or 0.0 (from the Float64 wrapper) depending on if defaulting is more valuable than repaying. It's used in the new_q function.\n",
    "\n",
    "I think this is an auxillary function though.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a22262a-63ce-47cc-a240-5d5036f82145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defFun (generic function with 1 method)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defFun(x) = Float64(vDefault(x[1]) > vRepay(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4077073b-fe2b-4650-9cea-3477a5c3d4a3",
   "metadata": {},
   "source": [
    "## 7.6: Associated log-likelihood functions\n",
    "\n",
    "For every single function that we want to approximate with a GPR, Zach defines an individual, specicialized function which serve as objective functions for the optimization procedure that finds each hyperparameters for each GPR. \n",
    "\n",
    "I.e. later in the code, we'll see lines like **rresultsVR = optimize(negLL_VR, init_kernCoeff, NelderMead())**\n",
    "\n",
    "Zach separates these functions out because it makes optimization calls cleaner, and crucially, allows each function to have its own set of optimized hyper-parameters, separate from the others!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a65aba2-59c1-4b8a-939c-70bd114a03ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negLL_A (generic function with 1 method)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negLL_VR(log_hyper_params) = negLL(log_hyper_params,tset_VR,2)\n",
    "negLL_VD(log_hyper_params) = negLL(log_hyper_params,tset_VD,1)\n",
    "negLL_q(log_hyper_params) = negLL(log_hyper_params,tset_q,2)\n",
    "negLL_A(log_hyper_params) = negLL(log_hyper_params,tset_A,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0609a8c-112e-447d-907f-d326ea856320",
   "metadata": {},
   "source": [
    "# 8. Defining model-specific objects\n",
    "\n",
    "These functions are the **true** functions calculated directly from the model's economic equations. They compute the actual values based on current approximations. I.e. they are what generate new training data for the GPRs. \n",
    "\n",
    "## 8.1 New bond pricing function\n",
    "\n",
    "This is a function that delivers the pricing function given current sovereign behavior in the next period.\n",
    "\n",
    "1. **zL1** and **zH1** are lower and upper bounds, which are centered around the expected log output for next period **ρy*log(current_y)**.\n",
    "2. **z_gc_points =  zL1 .+ ( 1.0 .+ gc_points)./2.0 .*(zH1-zL1)** transforms the Gauss-Chebyshev points from their original **[-1,1]** domain to the new new integration domain **[zL1, zH1]**.\n",
    "3. For each quadrature point (**1:quad_size**), the loop calculates the weighted probabiltiy contribution of default in that specific future output level. \n",
    "\n",
    "**ytempObj** is just a 1.0 or 0.0 - it stores the default decision.\n",
    "**sqrt(1.0-gc_points[iy]^2.0)** is a correction factor specific to Chebyshev quadrature.\n",
    "**normpdf((z_gc_points[iy] - ρy*log(current_y))/σy)/σy** is the probability density of this particular realization of future output, according to the AR(1) process.\n",
    "**/pdf_adj** adjustment factor to account for the trunction of the normal distribution, since we're only integrating over a 3.0 +/- std dev range.\n",
    "\n",
    "The sum of these points **sum(yvec)**, after being scaled for the integration domain domain with **(zH1-zL1)/2.0**, gives the probability of default.\n",
    "\n",
    "The final output is the bond price!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93ee6d81-4d30-4dc3-b11f-cf2f91aefc43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "new_q (generic function with 1 method)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function new_q(current_y,issued_b)\n",
    "\n",
    "    zL1 = ρy*log(current_y) - stds_out*σy\n",
    "    zH1 = ρy*log(current_y) + stds_out*σy\n",
    "\n",
    "    z_gc_points =  zL1 .+ ( 1.0 .+ gc_points)./2.0 .*(zH1-zL1)\n",
    "    yvec = copy(z_gc_points)\n",
    "\n",
    "    for iy=1:quad_size \n",
    "\n",
    "        ytempObj = defFun([exp(z_gc_points[iy]);issued_b])\n",
    "\n",
    "        yvec[iy] = gc_weights[iy]*ytempObj*sqrt(1.0-gc_points[iy]^2.0)*normpdf( (z_gc_points[iy] - ρy*log(current_y))/σy )/σy/pdf_adj\n",
    "\n",
    "    end \n",
    "    new_def1 = (zH1-zL1)/2.0*sum(yvec)\n",
    "\n",
    "    return (1.0-new_def1)/(1.0+r)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a2d097-c31e-4a00-bf1c-a5a62d6f5dfa",
   "metadata": {},
   "source": [
    "## 8.2. New value function for repayment\n",
    "\n",
    "Everything up to the for-loop is the exact same. Even most of the objects within the for-loop is the same too, it's just that instead of recording the default decisions, it's now recording the continuation value. Immediately outside the for-loop, **CV** is the expected continuation value.\n",
    "\n",
    "**flow_u** is the flow utility, or just u(c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f843869-5743-4a06-96b0-f0d03ab5af39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "new_VR (generic function with 1 method)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function new_VR(current_y,current_b, issued_b)\n",
    "\n",
    "    zL1 = ρy*log(current_y) - stds_out*σy\n",
    "    zH1 = ρy*log(current_y) + stds_out*σy\n",
    "\n",
    "    z_gc_points =  zL1 .+ ( 1.0 .+ gc_points)./2.0 .*(zH1-zL1)\n",
    "    yvec = copy(z_gc_points)\n",
    "\n",
    "    for iy=1:quad_size \n",
    "\n",
    "        ytempObj = max( vRepay([exp(z_gc_points[iy]);issued_b]), vDefault(exp(z_gc_points[iy]) ) )\n",
    "\n",
    "        yvec[iy] = gc_weights[iy]*ytempObj*sqrt(1.0-gc_points[iy]^2.0)*normpdf( (z_gc_points[iy] - ρy*log(current_y))/σy )/σy/pdf_adj\n",
    "\n",
    "    end \n",
    "    CV = (zH1-zL1)/2.0*sum(yvec)\n",
    "\n",
    "    flow_u = sov_utility( current_y - current_b + q([current_y;issued_b])*issued_b )\n",
    "\n",
    "    return flow_u + β*CV\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763a2e35-b552-4daf-b064-3dbe831b7037",
   "metadata": {},
   "source": [
    "## 8.3: New value function for default\n",
    "\n",
    "This really is all the same as the value function for repay, only expect that now, we need to account for the probability of re-entering financial markets or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "238f8429-879d-44e4-a655-8723bcadaa09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "new_VD (generic function with 1 method)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function new_VD(current_y)\n",
    "\n",
    "    zL1 = ρy*log(current_y) - stds_out*σy\n",
    "    zH1 = ρy*log(current_y) + stds_out*σy\n",
    "\n",
    "    z_gc_points =  zL1 .+ ( 1.0 .+ gc_points)./2.0 .*(zH1-zL1)\n",
    "    yvec = copy(z_gc_points)\n",
    "\n",
    "    for iy=1:quad_size \n",
    "\n",
    "        ytempObj = π_re_enter*vRepay([exp(z_gc_points[iy]);0.0]) + (1.0-π_re_enter)*vDefault(exp(z_gc_points[iy]) )\n",
    "\n",
    "        yvec[iy] = gc_weights[iy]*ytempObj*sqrt(1.0-gc_points[iy]^2.0)*normpdf( (z_gc_points[iy] - ρy*log(current_y))/σy )/σy/pdf_adj\n",
    "\n",
    "    end \n",
    "    CV = (zH1-zL1)/2.0*sum(yvec)\n",
    "\n",
    "    flow_u = sov_utility( ydef( current_y)  )\n",
    "\n",
    "    return flow_u + β*CV\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c2f052-f33c-44ab-96db-598a5f3f57ce",
   "metadata": {},
   "source": [
    "# 9: Value function iteration\n",
    "\n",
    "This is value function iteration operating as the limit of a finite-horizon game. I'm not sure what this means yet...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "632d34ab-fad9-4ea7-af5d-9d78dbdcf9be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_old_points = zeros(N_validate)\n",
    "v_new_points = zeros(N_validate)\n",
    "const conv_tol = 1.0e-6 \n",
    "ddist = 1.0\n",
    "iiters = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2ab21e9-1008-4fd5-9be4-cbc7c08045e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0 2.454682693372476]\n",
      "[2.0 1.1437133080271664]\n",
      "[3.0 1.0754592658763258]\n",
      "[4.0 1.0669422852443091]\n",
      "[5.0 1.012335233029006]\n",
      "[6.0 0.9425843647329799]\n",
      "[7.0 0.8762471172979787]\n",
      "[8.0 0.8358110392593829]\n",
      "[9.0 0.8058939333831887]\n",
      "[10.0 0.761173074497755]\n",
      "[11.0 0.7425961430738539]\n",
      "[12.0 0.6775979423138239]\n",
      "[13.0 0.6434304270386093]\n",
      "[14.0 0.6221677859306283]\n",
      "[15.0 0.5786808405785209]\n",
      "[16.0 0.5491957418061091]\n",
      "[17.0 0.5205818411628016]\n",
      "[18.0 0.4925122353363278]\n",
      "[19.0 0.46892135831389226]\n",
      "[20.0 0.44197107931725554]\n",
      "[21.0 0.4181125500953726]\n",
      "[22.0 0.3957399664449426]\n",
      "[23.0 0.3751527587957142]\n",
      "[24.0 0.35717358210365546]\n",
      "[25.0 0.33746154492081715]\n",
      "[26.0 0.32099050569821586]\n",
      "[27.0 0.3037475822746565]\n",
      "[28.0 0.28894087699800863]\n",
      "[29.0 0.2746346942714233]\n",
      "[30.0 0.26113152049028443]\n",
      "[31.0 0.24825271690610862]\n",
      "[32.0 0.23606187030713954]\n",
      "[33.0 0.22448908497934994]\n",
      "[34.0 0.2134833658644446]\n",
      "[35.0 0.20304412982334696]\n",
      "[36.0 0.1931206135004082]\n",
      "[37.0 0.18372187515130278]\n",
      "[38.0 0.1747792424867569]\n",
      "[39.0 0.16628335159787966]\n",
      "[40.0 0.15823900204155805]\n",
      "[41.0 0.15057642748439903]\n",
      "[42.0 0.14329435170610694]\n",
      "[43.0 0.13638057167376516]\n",
      "[44.0 0.1298038020592216]\n",
      "[45.0 0.12356185526728325]\n",
      "[46.0 0.1176162159972769]\n",
      "[47.0 0.11197110481961303]\n",
      "[48.0 0.1066031707869115]\n",
      "[49.0 0.10148998783150276]\n",
      "[50.0 0.09663942375595269]\n",
      "[51.0 0.09201945153629865]\n",
      "[52.0 0.08762319501302684]\n",
      "[53.0 0.08344265766898218]\n",
      "[54.0 0.07946339965518234]\n",
      "[55.0 0.07567515260856794]\n",
      "[56.0 0.07207448257626581]\n",
      "[57.0 0.0686431000712524]\n",
      "[58.0 0.06538229255840378]\n",
      "[59.0 0.06227579290867524]\n",
      "[60.0 0.059319803725180975]\n",
      "[61.0 0.056504479693266774]\n",
      "[62.0 0.0538256382935387]\n",
      "[63.0 0.05127221071098376]\n",
      "[64.0 0.04884408077172253]\n",
      "[65.0 0.04653034939351741]\n",
      "[66.0 0.04432844684878745]\n",
      "[67.0 0.04223051322838245]\n",
      "[68.0 0.04023437649800954]\n",
      "[69.0 0.03833130653239891]\n",
      "[70.0 0.036520235630902675]\n",
      "[71.0 0.03479503782223503]\n",
      "[72.0 0.033152687675798376]\n",
      "[73.0 0.03158760676863537]\n",
      "[74.0 0.030096012261950023]\n",
      "[75.0 0.03508342107372897]\n",
      "[76.0 0.027782180911223975]\n",
      "[77.0 0.026155538317730986]\n",
      "[78.0 0.024915977015890434]\n",
      "[79.0 0.02371015769238838]\n",
      "[80.0 0.022581921581565467]\n",
      "[81.0 0.02150952088522118]\n",
      "[82.0 0.020490009407055254]\n",
      "[83.0 0.019519756408016065]\n",
      "[84.0 0.018597237057615956]\n",
      "[85.0 0.017719638343137945]\n",
      "[86.0 0.016884590635999785]\n",
      "[87.0 0.01608994203406411]\n",
      "[88.0 0.015332854849283706]\n",
      "[89.0 0.014611478596510352]\n",
      "[90.0 0.013924072872466553]\n",
      "[91.0 0.013269147190506203]\n",
      "[92.0 0.0126453326662741]\n",
      "[93.0 0.01205072678683905]\n",
      "[94.0 0.011484232155897445]\n",
      "[95.0 0.010944249907861803]\n",
      "[96.0 0.010429887966967755]\n",
      "[97.0 0.009942190731727862]\n",
      "[98.0 0.009476669670110738]\n",
      "[99.0 0.009034286881782094]\n",
      "[100.0 0.008610892057610897]\n",
      "[101.0 0.008209071678418667]\n",
      "[102.0 0.007823489356642455]\n",
      "[103.0 0.007458904476049355]\n",
      "[104.0 0.007106986815877292]\n",
      "[105.0 0.006773537855362832]\n",
      "[106.0 0.00645749588931821]\n",
      "[107.0 0.006155743264123714]\n",
      "[108.0 0.005865830023527252]\n",
      "[109.0 0.005592242777751721]\n",
      "[110.0 0.005329064031244002]\n",
      "[111.0 0.005078781468796478]\n",
      "[112.0 0.0048409031322087515]\n",
      "[113.0 0.004613518615119716]\n",
      "[114.0 0.004397665999899658]\n",
      "[115.0 0.004192098889475915]\n",
      "[116.0 0.003994869973926285]\n",
      "[117.0 0.0038081760053003677]\n",
      "[118.0 0.0036283877707461443]\n",
      "[119.0 0.0034587089471358468]\n",
      "[120.0 0.003295521098500842]\n",
      "[121.0 0.0031410480134113072]\n",
      "[122.0 0.0029946843389367928]\n",
      "[123.0 0.002853329170260821]\n",
      "[124.0 0.0027195512874413907]\n",
      "[125.0 0.002592591243001152]\n",
      "[126.0 0.0024704272927742466]\n",
      "[127.0 0.002355645430800024]\n",
      "[128.0 0.0022428296133547576]\n",
      "[129.0 0.0021401090024042446]\n",
      "[130.0 0.0020377181088271357]\n",
      "[131.0 0.0019431796012909786]\n",
      "[132.0 0.0018502635245134513]\n",
      "[133.0 0.0017650205660579843]\n",
      "[134.0 0.0016836292922697282]\n",
      "[135.0 0.0016022815863756534]\n",
      "[136.0 0.0015279232599247905]\n",
      "[137.0 0.0014557868836568844]\n",
      "[138.0 0.0013885898869929747]\n",
      "[139.0 0.0013223507080724062]\n",
      "[140.0 0.0012584174595779984]\n",
      "[141.0 0.0012025713265266802]\n",
      "[142.0 0.0011436270665505788]\n",
      "[143.0 0.0010917399260499394]\n",
      "[144.0 0.0010386138179576676]\n",
      "[145.0 0.0009907801668411764]\n",
      "[146.0 0.0009452306575319369]\n",
      "[147.0 0.0009012722607160129]\n",
      "[148.0 0.0008578002476724578]\n",
      "[149.0 0.0008190816529953793]\n",
      "[150.0 0.0007787211616196998]\n",
      "[151.0 0.0007435545587917147]\n",
      "[152.0 0.0007084375998758219]\n",
      "[153.0 0.0006736481988056653]\n",
      "[154.0 0.0006428745728150886]\n",
      "[155.0 0.0006134323439574985]\n",
      "[156.0 0.00058365215149081]\n",
      "[157.0 0.0005579168406875112]\n",
      "[158.0 0.0005312964352199856]\n",
      "[159.0 0.0005058714127486041]\n",
      "[160.0 0.00048103312531821985]\n",
      "[161.0 0.00046074609023705193]\n",
      "[162.0 0.0004383606639102311]\n",
      "[163.0 0.00041788347950344473]\n",
      "[164.0 0.0003979733868639812]\n",
      "[165.0 0.00037896628539613175]\n",
      "[166.0 0.00036219045167840136]\n",
      "[167.0 0.00034342631933625967]\n",
      "[168.0 0.0003286198137715246]\n",
      "[169.0 0.0003134025811881713]\n",
      "[170.0 0.00029784931371779066]\n",
      "[171.0 0.00028482539735108503]\n",
      "[172.0 0.0002700052373150186]\n",
      "[173.0 0.00026026975399062735]\n",
      "[174.0 0.00024551357106616933]\n",
      "[175.0 0.00023516408962720448]\n",
      "[176.0 0.00022300185015922125]\n",
      "[177.0 0.00021225899999777198]\n",
      "[178.0 0.00020233035770189645]\n",
      "[179.0 0.00019430704168499346]\n",
      "[180.0 0.00018457073397826207]\n",
      "[181.0 0.00017677025198281626]\n",
      "[182.0 0.00016878318288959804]\n",
      "[183.0 0.00015922135041890328]\n",
      "[184.0 0.0001532091823044368]\n",
      "[185.0 0.0001454854008997586]\n",
      "[186.0 0.0001388983369885466]\n",
      "[187.0 0.00013231656146217574]\n",
      "[188.0 0.00012736462090146006]\n",
      "[189.0 0.00012040094436471804]\n",
      "[190.0 0.00011413233993806671]\n",
      "[191.0 0.00011134609622232006]\n",
      "[192.0 0.00010407032681669648]\n",
      "[193.0 9.8655173008666e-5]\n",
      "[194.0 9.472573382041105e-5]\n",
      "[195.0 9.028864629456734e-5]\n",
      "[196.0 8.587277200078347e-5]\n",
      "[197.0 8.205622425450088e-5]\n",
      "[198.0 7.90830148922339e-5]\n",
      "[199.0 7.40542955810497e-5]\n",
      "[200.0 7.108153655366323e-5]\n",
      "[201.0 6.889382663288757e-5]\n",
      "[202.0 6.503092292220458e-5]\n",
      "[203.0 6.107346479211628e-5]\n",
      "[204.0 5.934111755578897e-5]\n",
      "[205.0 5.6400580220383745e-5]\n",
      "[206.0 5.3020485729859956e-5]\n",
      "[207.0 5.223690996203345e-5]\n",
      "[208.0 4.969815810795808e-5]\n",
      "[209.0 4.661930178784246e-5]\n",
      "[210.0 4.409167724617191e-5]\n",
      "[211.0 4.478956749309759e-5]\n",
      "[212.0 4.1243257268064326e-5]\n",
      "[213.0 3.8265797261516354e-5]\n",
      "[214.0 3.6871699624185794e-5]\n",
      "[215.0 3.637391303001891e-5]\n",
      "[216.0 3.346475304510932e-5]\n",
      "[217.0 3.132757968771216e-5]\n",
      "[218.0 3.014937662015882e-5]\n",
      "[219.0 3.058619151374842e-5]\n",
      "[220.0 2.7791189015857753e-5]\n",
      "[221.0 2.629858447278366e-5]\n",
      "[222.0 2.516953521336518e-5]\n",
      "[223.0 2.470397797438295e-5]\n",
      "[224.0 2.3114451479955278e-5]\n",
      "[225.0 2.2207255575779072e-5]\n",
      "[226.0 2.0661362860607824e-5]\n",
      "[227.0 2.043068859336472e-5]\n",
      "[228.0 1.934476663123519e-5]\n",
      "[229.0 1.7929539239958103e-5]\n",
      "[230.0 1.7084616221296756e-5]\n",
      "[231.0 1.809599649149618e-5]\n",
      "[232.0 1.5453014473365556e-5]\n",
      "[233.0 1.600777518007135e-5]\n",
      "[234.0 1.4258945974177095e-5]\n",
      "[235.0 1.3603897425440437e-5]\n",
      "[236.0 1.378423793241268e-5]\n",
      "[237.0 1.2853848147642566e-5]\n",
      "[238.0 1.2135475355279368e-5]\n",
      "[239.0 1.1352493750393933e-5]\n",
      "[240.0 1.1478866525749254e-5]\n",
      "[241.0 1.0525999396548968e-5]\n",
      "[242.0 1.1049936038176611e-5]\n",
      "[243.0 9.405485084101883e-6]\n",
      "[244.0 9.24786474243433e-6]\n",
      "[245.0 8.636727098831898e-6]\n",
      "[246.0 8.345325163361395e-6]\n",
      "[247.0 7.987648903196032e-6]\n",
      "[248.0 8.10222267588756e-6]\n",
      "[249.0 7.5868668503176195e-6]\n",
      "[250.0 6.793958981177184e-6]\n",
      "[251.0 6.568220033642547e-6]\n",
      "[252.0 7.2622312146108925e-6]\n",
      "[253.0 6.858681011578938e-6]\n",
      "[254.0 6.1542417846283115e-6]\n",
      "[255.0 6.008361822296138e-6]\n",
      "[256.0 5.370818819017131e-6]\n",
      "[257.0 5.5058843528854595e-6]\n",
      "[258.0 4.575539605866652e-6]\n",
      "[259.0 4.936813532196993e-6]\n",
      "[260.0 4.914922001830746e-6]\n",
      "[261.0 4.416402493490068e-6]\n",
      "[262.0 4.24485958205878e-6]\n",
      "[263.0 3.90436617081491e-6]\n",
      "[264.0 4.948666276760605e-6]\n",
      "[265.0 4.233193067193497e-6]\n",
      "[266.0 3.952132800577601e-6]\n",
      "[267.0 4.7909999203454845e-6]\n",
      "[268.0 5.310814714221124e-6]\n",
      "[269.0 3.421129630254427e-6]\n",
      "[270.0 3.1049720377041012e-6]\n",
      "[271.0 4.1817317359971184e-6]\n",
      "[272.0 3.6094415847287564e-6]\n",
      "[273.0 3.1003863192324843e-6]\n",
      "[274.0 2.8724879754804533e-6]\n",
      "[275.0 3.956948230410262e-6]\n",
      "[276.0 2.738716119665696e-6]\n",
      "[277.0 3.4258560148714423e-6]\n",
      "[278.0 3.183823285013432e-6]\n",
      "[279.0 3.104708373058429e-6]\n",
      "[280.0 3.291041615227641e-6]\n",
      "[281.0 2.0693421269868395e-6]\n",
      "[282.0 2.494894040694362e-6]\n",
      "[283.0 4.0839502517542314e-6]\n",
      "[284.0 2.3029419544684515e-6]\n",
      "[285.0 1.6188218054935533e-6]\n",
      "[286.0 1.9663689805327067e-6]\n",
      "[287.0 1.8999837614330772e-6]\n",
      "[288.0 1.6285691266659796e-6]\n",
      "[289.0 1.4686386471396418e-6]\n",
      "[290.0 3.1839787126841657e-6]\n",
      "[291.0 2.8421307263215567e-6]\n",
      "[292.0 1.9755711875291126e-6]\n",
      "[293.0 1.6565673170987338e-6]\n",
      "[294.0 1.3767543229903367e-6]\n",
      "[295.0 1.2129119291159896e-6]\n",
      "[296.0 1.4072212124460748e-6]\n",
      "[297.0 1.3654379671379502e-6]\n",
      "[298.0 1.6261108264359336e-6]\n",
      "[299.0 1.08449430769042e-6]\n",
      "[300.0 1.4201645299749543e-6]\n",
      "[301.0 2.20245297555266e-6]\n",
      "[302.0 1.37943256461881e-6]\n",
      "[303.0 1.770268752920856e-6]\n",
      "[304.0 1.2570886696039452e-6]\n",
      "[305.0 2.6818201597222924e-6]\n",
      "[306.0 1.8285401317541528e-6]\n",
      "[307.0 2.6615107735494803e-6]\n",
      "[308.0 3.010617778187452e-6]\n",
      "[309.0 1.633654409971541e-6]\n",
      "[310.0 1.4540832715681518e-6]\n",
      "[311.0 1.6024884850196486e-6]\n",
      "[312.0 2.9657689175621726e-6]\n",
      "[313.0 1.6032946525967873e-6]\n",
      "[314.0 1.406512534884996e-6]\n",
      "[315.0 1.9163693494306244e-6]\n",
      "[316.0 2.236011074074895e-6]\n",
      "[317.0 1.0305301145763224e-6]\n",
      "[318.0 8.77216326244934e-7]\n"
     ]
    }
   ],
   "source": [
    "while ( (ddist > conv_tol) && (iiters < max_iters)) \n",
    "\n",
    "    global iiters += 1\n",
    "\n",
    "    convergence_points = drawConvergenceInputs(N_validate)\n",
    "    for i=1:N_validate \n",
    "        v_old_points[i] = vRepay(convergence_points[:,i])\n",
    "    end\n",
    "\n",
    "    #FIRST, we update the pricing equation (from penultimate period on)\n",
    "\n",
    "    #This is a pretty cool way to incorporate Andres' suggestion about using iteration numbers to change updating rules...\n",
    "    #Anyway, in the first iteration, (somewhat confusing in the else part, the initial guess of the pricing function is a fixed value.\n",
    "    #This basically pushes the bond price close to qL (high default probability)\n",
    "    #In subsequent iterations, the actual price is calculated with new_q(ytod,bissued)\n",
    "    #Notice that there are the min() and max() functions in there...\n",
    "    #There are there to bound the actual price to be between qL (the max part) and qH (the min part)\n",
    "    #There's also the 1.0e-6 - these offsets are just to prevent division by zero, or log(zeros) in the transformation)\n",
    "    for i=1:N_inputs \n",
    "        ytod = gridPoints[1,i]\n",
    "        bissued = gridPoints[2,i]\n",
    "        #Note the z suffix - these are logit-transformed!\n",
    "        if ( iiters > 1) \n",
    "            tset_qz[i] = -log((qH-qL)/(min( qH-1.0e-6, max( new_q(ytod,bissued), qL + 1.0e-6)-qL) ) - 1.0)\n",
    "        else \n",
    "            tset_qz[i] = -log((qH-qL)/(1.0e-6-qL) - 1.0)\n",
    "        end  \n",
    "    end\n",
    "    # SECONDLY we `clean' the outputs before running the GPR \n",
    "    #1. calculate the mean of all the logit-transformed pricing values\n",
    "    global mean_q = sum(tset_qz)/N_inputs\n",
    "    #2. Calculate the std deviatiopn of all these values\n",
    "    global std_q = sqrt( sum((tset_qz .- mean_q).^2.0)/(N_inputs-1.0) )\n",
    "    #This is a safety check to avoid division by very small numbers\n",
    "    if (std_q < 1.0e-6) \n",
    "        global std_q = 1.0 \n",
    "    end\n",
    "    #3. Create a normalized version (tset_q) by subtracting the mean and dividing it by the standard deviation\n",
    "    global tset_q = (tset_qz .- mean_q)./std_q\n",
    "\n",
    "    #4. We now have the updated training outputs for the bond pricing function - we can optimize the hyperparameters now\n",
    "    #Specifically, we updated one of the key inputs for negLL_q\n",
    "    #Optimizing the GP likelihood for the bond PRICING FUNCTION\n",
    "    global rresultsq = optimize(negLL_q,init_kernCoeff,NelderMead())\n",
    "\n",
    "    global opt_paramsq = rresultsq.minimizer \n",
    "    global opt_LLq = -rresultsq.minimum\n",
    "\n",
    "    global q_kernCoeff = 10.0.^opt_paramsq\n",
    "    global K_q = createK(q_kernCoeff,2)\n",
    "    global q_gprCoeff = (K_q .+ sn_star^2.0 .*eyeN)\\tset_q\n",
    "\n",
    "    # LASTLY, we update value and policy functions\n",
    "\n",
    "    #This is honestly, a pretty cool way to mix both continuous and discrete optimization\n",
    "     for i=1:N_inputs \n",
    "        #Initializing the specific point within the state-space\n",
    "        ytod = gridPoints[1,i]\n",
    "        btod = gridPoints[2,i]\n",
    "\n",
    "        #1.This part implements the optimization on a DISCRETE grid\n",
    "        #Remember that earlier, Zach initialized a 50-element grid of possible choices for debt issuance \n",
    "        vtemp = zeros(bN_opt)\n",
    "        max_i = 1\n",
    "        best_v = -1.0e10 #Negative number that is massive in scale\n",
    "        #Calculating the value in everything within the b_opt_grid\n",
    "        for iopt=1:bN_opt\n",
    "            vtemp[iopt] = new_VR(ytod,btod, b_opt_grid[iopt])\n",
    "            #As my code loops through each possible debt level in the discrete grid, it calculates the value of repayment in that choice\n",
    "            #As a better value gets calculated, best_v gets updated!\n",
    "            if (vtemp[iopt] >= best_v) \n",
    "                best_v = vtemp[iopt]\n",
    "                max_i = iopt \n",
    "            end \n",
    "        end\n",
    "        #2. This part of the code refines the solution with CONTINUOUS optimization\n",
    "        #First, upper and lower bounds for the optimization are created\n",
    "        bL_local = bLopt \n",
    "        bH_local = bHopt\n",
    "        if (max_i == 1) \n",
    "            bL_local = bLopt\n",
    "            bH_local = b_opt_grid[2]\n",
    "        elseif (max_i == bN_opt)  \n",
    "            bL_local = b_opt_grid[bN_opt-1]\n",
    "            bH_local = b_opt_grid[bN_opt]\n",
    "        else \n",
    "            bL_local = b_opt_grid[max_i-1]\n",
    "            bH_local = b_opt_grid[max_i+1]\n",
    "        end \n",
    "        #Defining the function to be optimized\n",
    "        v_obj(bprime) = -new_VR(ytod,btod,bprime)\n",
    "        #Continuous optimization\n",
    "        rresults = optimize(v_obj,bL_local,bH_local)\n",
    "        #Storing the value function\n",
    "        vnew = -rresults.minimum \n",
    "        #Storing the policy function\n",
    "        anew = rresults.minimizer\n",
    "\n",
    "        #We have the value function and policy function training data in normal form, now let's logit transform it\n",
    "        tset_VRz[i] = -log((VH-VL)/(vnew-VL) - 1.0)\n",
    "        tset_Az[i] = -log((bH-bL)/(anew-bL) - 1.0)\n",
    "\n",
    "        #Updating the training data for the value of defaulting\n",
    "        vdnew = new_VD(ytod)\n",
    "        #Then, logit transforming it\n",
    "        tset_VDz[i] = -log((VH-VL)/(vdnew-VL) - 1.0)\n",
    "\n",
    "    end \n",
    "    \n",
    "    # Now we `clean' the outputs before running the GPR \n",
    "    global mean_VR = sum(tset_VRz)/N_inputs\n",
    "    global std_VR = sqrt( sum((tset_VRz .- mean_VR).^2.0)/(N_inputs-1.0) )\n",
    "    if (std_VR < 1.0e-6) \n",
    "        global std_VR = 1.0 \n",
    "    end\n",
    "    global tset_VR = (tset_VRz .- mean_VR)./std_VR\n",
    "\n",
    "    global mean_VD = sum(tset_VDz)/N_inputs\n",
    "    global std_VD = sqrt( sum((tset_VDz .- mean_VD).^2.0)/(N_inputs-1.0) )\n",
    "    if (std_VD < 1.0e-6) \n",
    "        global std_VD = 1.0 \n",
    "    end\n",
    "    global tset_VD = (tset_VDz .- mean_VD)./std_VD\n",
    "\n",
    "    global mean_A = sum(tset_Az)/N_inputs\n",
    "    global std_A = sqrt( sum((tset_Az .- mean_A).^2.0)/(N_inputs-1.0) )\n",
    "    if (std_A < 1.0e-6) \n",
    "        global std_A = 1.0 \n",
    "    end\n",
    "    global tset_A = (tset_Az .- mean_A)./std_A\n",
    "\n",
    "    # Now, we optimize all the GP likelihoods and get the new functions\n",
    "    #1. Optimizing the GP likelihood of the value function for REPAYING\n",
    "    global rresultsVR = optimize(negLL_VR,init_kernCoeff,NelderMead())\n",
    "\n",
    "    global opt_paramsVR = rresultsVR.minimizer \n",
    "    global opt_LLVR = -rresultsVR.minimum\n",
    "\n",
    "    global VR_kernCoeff = 10.0.^opt_paramsVR\n",
    "    global K_VR = createK(VR_kernCoeff,2)\n",
    "    global VR_gprCoeff = (K_VR .+ sn_star^2.0 .*eyeN)\\tset_VR\n",
    "\n",
    "    #2. Optimizing the GP likelihood of the value function for DEFAULTING\n",
    "    global rresultsVD = optimize(negLL_VD,init_kernCoeff,NelderMead())\n",
    "\n",
    "    global opt_paramsVD = rresultsVD.minimizer \n",
    "    global opt_LLVD = -rresultsVD.minimum\n",
    "\n",
    "    global VD_kernCoeff = 10.0.^opt_paramsVD\n",
    "    global K_VD = createK(VD_kernCoeff,1)\n",
    "    global VD_gprCoeff = (K_VD .+ sn_star^2.0 .*eyeN)\\tset_VD\n",
    "\n",
    "    #3. Optimizing the GP likelihood of the bond issuance POLICY FUNCTION\n",
    "    global rresultsA = optimize(negLL_A,init_kernCoeff,NelderMead())\n",
    "\n",
    "    global opt_paramsA = rresultsA.minimizer \n",
    "    global opt_LLA = -rresultsA.minimum\n",
    "\n",
    "    global A_kernCoeff = 10.0.^opt_paramsA\n",
    "    global K_A = createK(A_kernCoeff,2)\n",
    "    global A_gprCoeff = (K_A .+ sn_star^2.0 .*eyeN)\\tset_A\n",
    "\n",
    "\n",
    "    # Now update the value function and check for convergence\n",
    "    for i=1:N_validate \n",
    "        v_new_points[i] = vRepay(convergence_points[:,i])\n",
    "    end\n",
    "    global ddist = maximum(abs.(v_new_points .- v_old_points))\n",
    "    println([iiters ddist])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ce4979-4411-4091-b5ed-3f893f4ec1ae",
   "metadata": {},
   "source": [
    "# 9. Plots\n",
    "Finally, Zach wraps things up by plotting the equilibrium objects. It gets reduced to a two-dimensional plot for interpretability. Specifically, three lines are plotted - steady state output (y = 1.0), low output (y = 0.9), and high output (y = 1.1).\n",
    "## 9.1 Pricing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e122ac-91d9-4253-b920-ec33f85828dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the solved policy and pricing functions\n",
    "bN_plot = 500\n",
    "b_plot_grid = bLopt:(bHopt-bLopt)/(bN_plot-1):bHopt\n",
    "\n",
    "q_plot = zeros(bN_plot)\n",
    "VR_plot = zeros(bN_plot)\n",
    "VD_plot = zeros(bN_plot)\n",
    "A_plot = zeros(bN_plot)\n",
    "for i=1:bN_plot \n",
    "    q_plot[i] = q([1.0;b_plot_grid[i]])\n",
    "    VR_plot[i] = vRepay([1.0;b_plot_grid[i]])\n",
    "    A_plot[i] = Apol([1.0;b_plot_grid[i]])\n",
    "    VD_plot[i] = vDefault(1.0)\n",
    "end\n",
    "\n",
    "b_grid = bL:.001:bH\n",
    "# b_grid = bL:.03:bH\n",
    "q_ss(b) = q([1.0, b])\n",
    "q_l(b) = q([0.9, b])\n",
    "q_h(b) = q([1.1, b])\n",
    "plot(b_grid,q_ss.(b_grid),label=\"SS Output\",xlabel=\"Debt Issuance\",ylabel=\"Price\")\n",
    "plot!(b_grid,q_l.(b_grid),label=\"Low Output\")\n",
    "plot!(b_grid,q_h.(b_grid),label=\"High Output\")\n",
    "\n",
    "#savefig(\"pricing_functions_arellano_2008.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a3ab65-49c5-4909-b936-7e93b82e8f97",
   "metadata": {},
   "source": [
    "## 9.2 Bond issuance policy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "396fe373-3ef4-480d-89cb-c89fbd208b31",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `plot` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `plot` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[1]:3"
     ]
    }
   ],
   "source": [
    "a_b_alone_h(b) = Apol([1.1, b])\n",
    "a_b_alone_l(b) = Apol([0.9, b])\n",
    "plot(b_grid,a_b_alone_h.(b_grid),label=\"High Output\",ylabel=\"Debt Issuance\",xlabel=\"Debt Stock\")\n",
    "plot!(b_grid,a_b_alone_l.(b_grid),label=\"Low Output\")\n",
    "\n",
    "#savefig(\"policy_functions_arellano_2008.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535f3a3e-78ce-4b95-b31b-3f5662da57d7",
   "metadata": {},
   "source": [
    "## 9.3 Value functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d93df9e8-f625-481c-90ea-03e87503c01c",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `yL` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `yL` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[2]:1"
     ]
    }
   ],
   "source": [
    "y_grid = yL:.001:yH\n",
    "btest = 0.2\n",
    "V_y_alone(y) = vRepay([y; btest])\n",
    "Vd_y_alone(y) = vDefault(y)\n",
    "\n",
    "plot(y_grid,V_y_alone.(y_grid),xlabel=\"Output\",label=\"Repayment Value\")\n",
    "plot!(y_grid,Vd_y_alone.(y_grid),label=\"Default Value\")\n",
    "\n",
    "#savefig(\"Value_functions_y_arellano_2008.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
